{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4xOsFiu-1-c"
   },
   "source": [
    "# Music Generation with RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZniYb7Y_0Ey"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt && echo \"Dependencies installed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GsLFq7nsiqcq"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "import fluidsynth\n",
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzIbfb-Ikgg7"
   },
   "source": [
    "## Download the Maestro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Efja_OtJNzAM"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Sampling rate for audio playback\n",
    "_SAMPLING_RATE = 16000\n",
    "\n",
    "\n",
    "FILE_COUNT = 0.75 #range 0-1, total file to use from dataset for training\n",
    "\n",
    "SEQ_LENGTH = 25\n",
    "\n",
    "EPOCHS = 27\n",
    "\n",
    "BATHC_SIZE = 512\n",
    "\n",
    "BUFFER_SIZE = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "DATASET_NAME = \"maestro-v2.0.0\"\n",
    "DATASET_FILE = f\"{DATASET_NAME}-midi.zip\"\n",
    "DATASET_URL = (\n",
    "    f\"https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/{DATASET_FILE}\"\n",
    ")\n",
    "CACHE_DIR = \".\"\n",
    "CACHE_SUBDIR = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwja4SWmibrL"
   },
   "outputs": [],
   "source": [
    "#Download\n",
    "data_dir = pathlib.Path(f\"{CACHE_SUBDIR}/{DATASET_NAME}\")\n",
    "if not data_dir.exists():\n",
    "    tf.keras.utils.get_file(\n",
    "        DATASET_FILE,\n",
    "        origin=DATASET_URL,\n",
    "        extract=True,\n",
    "        cache_dir=CACHE_DIR,\n",
    "        cache_subdir=CACHE_SUBDIR,\n",
    "    )\n",
    "    print(f\"Downloaded and extracted {DATASET_NAME}\")\n",
    "else:\n",
    "    print(f\"{DATASET_NAME} already exists and skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72iFI1bPB9o1"
   },
   "outputs": [],
   "source": [
    "import pathlib, glob, os\n",
    "\n",
    "#Auto-detect extracted dataset folder\n",
    "CACHE_SUBDIR = \"data\"\n",
    "data_root = pathlib.Path(CACHE_SUBDIR)\n",
    "possible_dirs = [d for d in data_root.iterdir() if d.is_dir() and \"maestro\" in d.name.lower()]\n",
    "\n",
    "if possible_dirs:\n",
    "    data_dir = possible_dirs[0]\n",
    "    print(f\"Using dataset folder: {data_dir}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"MAESTRO dataset folder not found!\")\n",
    "\n",
    "#Collect all MIDI file paths\n",
    "filenames = glob.glob(os.path.join(str(data_dir), \"**\", \"*.mid*\"), recursive=True)\n",
    "print(f\"Found {len(filenames)} MIDI files.\")\n",
    "\n",
    "# Alias\n",
    "midi_files = filenames  #same reference & this is not a copy;\n",
    "sample_file = midi_files[0]\n",
    "print(f\"Sample file: {sample_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BlRafYDIRgA"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Display Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzoHAaVY_kyY"
   },
   "outputs": [],
   "source": [
    "def display_audio(pm: pretty_midi.PrettyMIDI, seconds=30):\n",
    "  waveform = pm.fluidsynth(fs=_SAMPLING_RATE)\n",
    "  waveform_short = waveform[:seconds*_SAMPLING_RATE]\n",
    "  return display.Audio(waveform_short, rate=_SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Midid -> Notes Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wyp_wdcEPWby"
   },
   "outputs": [],
   "source": [
    "def midi_to_notes(midi_file: str) -> pd.DataFrame:\n",
    "  pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "  instrument = pm.instruments[0]\n",
    "  notes = collections.defaultdict(list)\n",
    "\n",
    "  # Sort the notes by start time\n",
    "  sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
    "  prev_start = sorted_notes[0].start\n",
    "\n",
    "  for note in sorted_notes:\n",
    "    start = note.start\n",
    "    end = note.end\n",
    "    notes['pitch'].append(note.pitch)\n",
    "    notes['start'].append(start)\n",
    "    notes['end'].append(end)\n",
    "    notes['step'].append(start - prev_start)\n",
    "    notes['duration'].append(end - start)\n",
    "    prev_start = start\n",
    "\n",
    "  return pd.DataFrame({name: np.array(value) for name, value in notes.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number->Human Readable Notes Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WE9YXrGZbY2X"
   },
   "outputs": [],
   "source": [
    "get_note_names = np.vectorize(pretty_midi.note_number_to_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Piano Roll Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liD2N7x_WOTp"
   },
   "outputs": [],
   "source": [
    "def plot_piano_roll(notes: pd.DataFrame, count: Optional[int] = None):\n",
    "  if count:\n",
    "    title = f'First {count} notes'\n",
    "  else:\n",
    "    title = f'Whole track'\n",
    "    count = len(notes['pitch'])\n",
    "  plt.figure(figsize=(20, 4))\n",
    "  plot_pitch = np.stack([notes['pitch'], notes['pitch']], axis=0)\n",
    "  plot_start_stop = np.stack([notes['start'], notes['end']], axis=0)\n",
    "  plt.plot(\n",
    "      plot_start_stop[:, :count], plot_pitch[:, :count], color=\"b\", marker=\".\")\n",
    "  plt.xlabel('Time [s]')\n",
    "  plt.ylabel('Pitch')\n",
    "  _ = plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Distribution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pq9C9XBBaK7W"
   },
   "outputs": [],
   "source": [
    "def plot_distributions(notes: pd.DataFrame, drop_percentile=2.5):\n",
    "  plt.figure(figsize=[15, 5])\n",
    "  plt.subplot(1, 3, 1)\n",
    "  sns.histplot(notes, x=\"pitch\", bins=20)\n",
    "\n",
    "  plt.subplot(1, 3, 2)\n",
    "  max_step = np.percentile(notes['step'], 100 - drop_percentile)\n",
    "  sns.histplot(notes, x=\"step\", bins=np.linspace(0, max_step, 21))\n",
    "  \n",
    "  plt.subplot(1, 3, 3)\n",
    "  max_duration = np.percentile(notes['duration'], 100 - drop_percentile)\n",
    "  sns.histplot(notes, x=\"duration\", bins=np.linspace(0, max_duration, 21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes-> Midi Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BD5rsMRARYoV"
   },
   "outputs": [],
   "source": [
    "def notes_to_midi(\n",
    "  notes: pd.DataFrame,\n",
    "  out_file: str, \n",
    "  instrument_name: str,\n",
    "  velocity: int = 100,  # note loudness\n",
    ") -> pretty_midi.PrettyMIDI:\n",
    "\n",
    "  pm = pretty_midi.PrettyMIDI()\n",
    "  instrument = pretty_midi.Instrument(\n",
    "      program=pretty_midi.instrument_name_to_program(\n",
    "          instrument_name))\n",
    "\n",
    "  prev_start = 0\n",
    "  for i, note in notes.iterrows():\n",
    "    start = float(prev_start + note['step'])\n",
    "    end = float(start + note['duration'])\n",
    "    note = pretty_midi.Note(\n",
    "        velocity=velocity,\n",
    "        pitch=int(note['pitch']),\n",
    "        start=start,\n",
    "        end=end,\n",
    "    )\n",
    "    instrument.notes.append(note)\n",
    "    prev_start = start\n",
    "\n",
    "  pm.instruments.append(instrument)\n",
    "  pm.write(out_file)\n",
    "  return pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence creating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(\n",
    "    dataset: tf.data.Dataset, \n",
    "    seq_length: int,\n",
    "    vocab_size = 128,\n",
    ") -> tf.data.Dataset:\n",
    "  \"\"\"Returns TF Dataset of sequence and label examples.\"\"\"\n",
    "  seq_length = seq_length+1\n",
    "\n",
    "  # Take 1 extra for the labels\n",
    "  windows = dataset.window(seq_length, shift=1, stride=1,\n",
    "                              drop_remainder=True)\n",
    "\n",
    "  # `flat_map` flattens the\" dataset of datasets\" into a dataset of tensors\n",
    "  flatten = lambda x: x.batch(seq_length, drop_remainder=True)\n",
    "  sequences = windows.flat_map(flatten)\n",
    "  \n",
    "  # Normalize note pitch\n",
    "  def scale_pitch(x):\n",
    "    x = x/[vocab_size,1.0,1.0]\n",
    "    return x\n",
    "\n",
    "  # Split the labels\n",
    "  def split_labels(sequences):\n",
    "    inputs = sequences[:-1]\n",
    "    labels_dense = sequences[-1]\n",
    "    labels = {key:labels_dense[i] for i,key in enumerate(key_order)}\n",
    "\n",
    "    return scale_pitch(inputs), labels\n",
    "\n",
    "  return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfRNk9tEScuf"
   },
   "source": [
    "## Creating the training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GiaQiTnXSW-T"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "num_files = int(len(filenames) * FILE_COUNT) #total files to use from dataset for training;\n",
    "subset = np.random.choice(filenames, num_files, replace=False)\n",
    "\n",
    "print(f\"Processing {num_files} random MIDI files...\")\n",
    "\n",
    "results = []\n",
    "for f in tqdm(subset, desc=\"Processing MIDI files\"):\n",
    "    try:\n",
    "        df = midi_to_notes(f)  \n",
    "        results.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {f}: {e}\")\n",
    "\n",
    "#Combine all\n",
    "all_notes = pd.concat(results, ignore_index=True)\n",
    "print(f\"Done. Combined shape: {all_notes.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4bMDeRvgWqx"
   },
   "outputs": [],
   "source": [
    "n_notes = len(all_notes)\n",
    "print('Number of notes parsed:', n_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvNHCHZdXG2P"
   },
   "outputs": [],
   "source": [
    "key_order = ['pitch', 'step', 'duration']\n",
    "train_notes = np.stack([all_notes[key] for key in key_order], axis=1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLC_19tshyFk"
   },
   "outputs": [],
   "source": [
    "notes_ds = tf.data.Dataset.from_tensor_slices(train_notes)\n",
    "print(notes_ds.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGA3VxcFXZ4T"
   },
   "outputs": [],
   "source": [
    "seq_length = SEQ_LENGTH\n",
    "vocab_size = 128\n",
    "seq_ds = create_sequences(notes_ds, seq_length, vocab_size)\n",
    "seq_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESK9cL7__TF3"
   },
   "outputs": [],
   "source": [
    "for seq, target in seq_ds.take(1):\n",
    "  print('sequence shape:', seq.shape)\n",
    "  print('sequence elements (first 10):', seq[0: 10])\n",
    "  print()\n",
    "  print('target:', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTpFoiM_AV_Y"
   },
   "outputs": [],
   "source": [
    "batch_size = BATHC_SIZE\n",
    "buffer_size = BUFFER_SIZE\n",
    "\n",
    "train_ds = (seq_ds\n",
    "            .cache()\n",
    "            .shuffle(buffer_size)\n",
    "            .batch(batch_size, drop_remainder=True)\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWZmfkshqP8G"
   },
   "source": [
    "## Create and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "erxLOif08e8v"
   },
   "outputs": [],
   "source": [
    "def mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
    "  mse = (y_true - y_pred) ** 2\n",
    "  positive_pressure = 10 * tf.maximum(-y_pred, 0.0)\n",
    "  return tf.reduce_mean(mse + positive_pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kNaVWcCzAm5V"
   },
   "outputs": [],
   "source": [
    "input_shape = (seq_length, 3)\n",
    "learning_rate = 0.005\n",
    "\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "x = tf.keras.layers.LSTM(128)(inputs)\n",
    "\n",
    "outputs = {\n",
    "  'pitch': tf.keras.layers.Dense(128, name='pitch')(x),\n",
    "  'step': tf.keras.layers.Dense(1, name='step')(x),\n",
    "  'duration': tf.keras.layers.Dense(1, name='duration')(x),\n",
    "}\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "loss = {\n",
    "      'pitch': tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "          from_logits=True),\n",
    "      'step': mse_with_positive_pressure,\n",
    "      'duration': mse_with_positive_pressure,\n",
    "}\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlATt7Rl0XJl"
   },
   "outputs": [],
   "source": [
    "losses = model.evaluate(train_ds, return_dict=True)\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fQB5SiN3ufX"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=loss,\n",
    "    loss_weights={\n",
    "        'pitch': 0.05,\n",
    "        'step': 1.0,\n",
    "        'duration':1.0,\n",
    "    },\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7CzWmFR38ut"
   },
   "outputs": [],
   "source": [
    "model.evaluate(train_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU available:\", tf.test.is_gpu_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQA_rwKEgPjp"
   },
   "outputs": [],
   "source": [
    "print(model.output_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLoYY8-XaPFN"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=loss,\n",
    "    loss_weights={\n",
    "        'pitch': 0.05,\n",
    "        'step': 1.0,\n",
    "        'duration':1.0,\n",
    "    },\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = EPOCHS\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history['loss'], label='total loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = \"music_rnn_model.keras\"\n",
    "model.save(FILE_NAME)\n",
    "print(f\"Model saved successfully as {FILE_NAME}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "music_generation.ipynb",
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
